import os
import re
import json
import shutil
import subprocess
import platform
from shutil import which
import speech_recognition as sr
try:
    import requests
except Exception:
    requests = None
import streamlit as st
from unicodedata import normalize
from PIL import Image
import matplotlib.pyplot as plt
import time
import urllib.request
from threading import Lock
from datetime import datetime
from difflib import SequenceMatcher
import random
import seaborn as sns
import colorama
import threading
from colorama import Fore, Style
colorama.init(autoreset=True)

status_lock = Lock()  # lock global de escrita

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.1:3b")
OLLAMA_CLI = os.getenv("OLLAMA_CLI", "ollama")
OLLAMA_NUM_PREDICT = int(os.getenv("OLLAMA_NUM_PREDICT", "40"))
OLLAMA_TEMPERATURE = float(os.getenv("OLLAMA_TEMPERATURE", "0.2"))
OLLAMA_TOP_P = float(os.getenv("OLLAMA_TOP_P", "0.9"))
OLLAMA_NUM_CTX = int(os.getenv("OLLAMA_NUM_CTX", "256"))
OLLAMA_KEEP_ALIVE = os.getenv("OLLAMA_KEEP_ALIVE", "10m")
if platform.system() == "Windows":
    ADB_PATH = r"C:\Users\Automation01\platform-tools\adb.exe"
else:
    ADB_PATH = "adb"



def _resolve_ollama_cli() -> str:
    path = which(OLLAMA_CLI)
    if path:
        return path
    local_app = os.getenv("LOCALAPPDATA", "")
    candidate = os.path.join(local_app, "Programs", "Ollama", "ollama.exe")
    if candidate and os.path.exists(candidate):
        return candidate
    return OLLAMA_CLI




def _warmup_ollama():
    def _run():
        try:
            _ollama_generate("Responda apenas com 'ok'.", timeout_s=8, allow_cli=False)
        except Exception:
            pass
    t = threading.Thread(target=_run, daemon=True)
    t.start()

# aquece o modelo uma vez por sess?o
if "ollama_warm" not in st.session_state:
    st.session_state["ollama_warm"] = True
    _warmup_ollama()

def configurar_reconhecedor() -> sr.Recognizer:
    r = sr.Recognizer()
    # torna o nÃ­vel de corte adaptativo ao ruÃ­do
    r.dynamic_energy_threshold = True
    # base razoÃ¡vel; serÃ¡ recalibrado pelo adjust_for_ambient_noise
    r.energy_threshold = 250
    # tolerÃ¢ncia para pequenas pausas no meio da frase
    r.pause_threshold = 0.9
    # considera silÃªncio curtinho antes de encerrar
    r.non_speaking_duration = 0.3
    return r

def normalizar_pos_fala(txt: str) -> str:
    # correÃ§Ãµes comuns da fala -> texto
    m = {
        "executa": "executar",
        "rode": "rodar",
        "voltar ": "resetar ",
        "volta ": "resetar ",
        "reset ": "resetar ",
        "geral um": "geral 1",
        "geral dois": "geral 2",
        "geral tres": "geral 3",
        "bancada um": "bancada 1",
        "bancada dois": "bancada 2",
        "bancada trÃªs": "bancada 3",
        "na bancada um": "na bancada 1",
        "na bancada dois": "na bancada 2",
        "na bancada trÃªs": "na bancada 3",
        "rodar todos os teste": "rodar todos os testes",
        "listar a bancada": "listar bancadas",
        "listar bancada": "listar bancadas",
    }
    s = txt.strip().lower()
    for k, v in m.items():
        s = s.replace(k, v)
    # se vocÃª jÃ¡ tem _replace_number_words/_norm, aplique aqui tambÃ©m se quiser:
    # s = _replace_number_words(s)
    return s

def titulo_painel(titulo: str, subtitulo: str = ""):
    st.markdown(
        f"""
        <style>
        .main-title {{
            font-size: 2.5rem;
            text-align: center;
            background: linear-gradient(90deg, #12c2e9, #c471ed, #f64f59);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 700;
            letter-spacing: -0.5px;
            margin-bottom: 0.3em;
        }}
        .subtitle {{
            text-align: center;
            color: #AAAAAA;
            font-size: 1rem;
            margin-bottom: 1.8em;
        }}
        </style>
        <h1 class="main-title">{titulo}</h1>
        <p class="subtitle">{subtitulo}</p>
        """,
        unsafe_allow_html=True
    )

def printc(msg, color="white"):
    """
    Imprime mensagens coloridas no terminal e retorna string limpa para uso no Streamlit.
    """
    colors = {
        "green": Fore.GREEN,
        "yellow": Fore.YELLOW,
        "red": Fore.RED,
        "white": Style.RESET_ALL,
        "cyan": Fore.CYAN,
        "blue": Fore.BLUE
    }
    print(f"{colors.get(color, '')}{msg}{Style.RESET_ALL}", flush=True)
    return msg  # opcional: retorna a string limpa, Ãºtil se quiser exibir no chat

# === CONFIGURAÃ‡Ã•ES ===
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_ROOT = os.path.join(BASE_DIR, "Data")
RUN_SCRIPT = os.path.join(BASE_DIR, "Run", "run_noia.py")
COLETOR_SCRIPT = os.path.join(BASE_DIR, "Scripts", "coletor_adb.py")
PROCESSAR_SCRIPT = os.path.join(BASE_DIR, "Pre_process", "processar_dataset.py")
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
PAUSE_FLAG_PATH = os.path.join(PROJECT_ROOT, "pause.flag")
STATUS_PATH = os.path.join(DATA_ROOT, "status_bancadas.json")

# === MODO CONVERSACIONAL ===
MODO_CONVERSA = True  # Altere para False se quiser desativar as respostas naturais


st.set_page_config(page_title="Agente de Testes", page_icon="ğŸ¤–", layout="wide")


# === SESSION STATE ===
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "coletas_ativas" not in st.session_state:
    st.session_state.coletas_ativas = set()
if "coleta_atual" not in st.session_state:
    st.session_state.coleta_atual = None
if "pending_gravacao" not in st.session_state:
    st.session_state.pending_gravacao = None
if "finalizacoes_pendentes" not in st.session_state:
    st.session_state.finalizacoes_pendentes = []

# =========================
# === SUPORTE A BANCADAS ===
# =========================
def _parse_adb_devices(raw_lines):
    """
    Converte a saÃ­da do 'adb devices' em lista de seriais vÃ¡lidos.
    Considera apenas linhas que terminam com 'device' (online).
    """
    seriais = []
    for ln in raw_lines[1:]:  # pula a primeira linha "List of devices attached"
        ln = ln.strip()
        # Ex: "R58M12345AB\tdevice"
        m = re.match(r"^(\S+)\s+device$", ln)
        if m:
            seriais.append(m.group(1))
    return seriais


def listar_bancadas():
    """Mapeia dispositivos adb em bancadas numeradas: {'1': serial1, '2': serial2, ...}"""
    try:
        result = subprocess.check_output(["adb", "devices"], text=True).strip().splitlines()
        devices = _parse_adb_devices(result)
        return {str(i + 1): dev for i, dev in enumerate(devices)}
    except Exception:
        return {}

def _formatar_bancadas_str(bancadas: dict) -> str:
    if not bancadas:
        return "ğŸ“¡ Nenhuma bancada conectada."
    linhas = ["ğŸ“¡ **Bancadas disponÃ­veis:**"]
    for k, v in bancadas.items():
        linhas.append(f"{k} â†’ `{v}`")
    return "\n".join(linhas)

def _resolver_teste(nome_ou_token: str):
    """
    Localiza (categoria, teste) em Data/<categoria>/<teste> aceitando variaÃ§Ãµes:
    'geral2' == 'geral_2' == 'geral-2' == 'geral 2' == 'geral um'.
    """
    if not nome_ou_token:
        return None, None

    alvo_norm = _normalize_token(nome_ou_token)

    cats = listar_categorias()

    # 1) Busca direta por equivalÃªncia normalizada em todas as categorias
    for cat in cats:
        for t in listar_testes(cat):
            if _normalize_token(t) == alvo_norm:
                return cat, t

    # 2) Caso o token venha no formato "categoria_nome" (com qualquer separador)
    parts = re.split(r"[_\-\s]+", _norm(nome_ou_token))
    if parts:
        cand_cat = parts[0]
        if cand_cat in cats:
            resto_norm = _normalize_token("".join(parts[1:]))  # sÃ³ o nome do teste
            for t in listar_testes(cand_cat):
                if _normalize_token(t) in (alvo_norm, resto_norm):
                    return cand_cat, t

    # 3) Fallback: fuzzy match leve (>= 0,92) entre nomes normalizados
    candidatos = []
    for cat in cats:
        for t in listar_testes(cat):
            if SequenceMatcher(None, _normalize_token(t), alvo_norm).ratio() >= 0.92:
                candidatos.append((cat, t))
    if len(candidatos) == 1:
        return candidatos[0]

    return None, None

def _selecionar_bancada(bancada: str | None, bancadas: dict):
    """
    Seleciona o serial a partir da 'bancada' informada.
    Regras:
      - 'todas' => retorna lista com todos os seriais (paralelo)
      - nÃºmero vÃ¡lido => retorna lista com um serial
      - None => pega a primeira disponÃ­vel (se houver)
    Retorna (lista_de_seriais, mensagem_erro_ou_None)
    """
    if not bancadas:
        return [], "âŒ Nenhuma bancada conectada."

    if bancada is None or str(bancada).strip() == "":
        # primeira disponÃ­vel
        return [bancadas[sorted(bancadas.keys(), key=int)[0]]], None

    txt = str(bancada).strip().lower()
    if txt in ("todas", "todas as bancadas", "todas-bancadas", "all"):
        return list(bancadas.values()), None

    if txt.isdigit() and txt in bancadas:
        return [bancadas[txt]], None

    return [], f"âŒ Bancada '{bancada}' nÃ£o encontrada. Use **listar bancadas**."

def _popen_host_python(cmd):
    """Wrapper para subprocess.Popen no host (sem adb shell)."""
    try:
        subprocess.Popen(cmd, cwd=BASE_DIR)
        return True, None
    except Exception as e:
        return False, f"Falha ao executar comando: {e}"

def atualizar_status_bancada(serial, status, teste=None):
    """Atualiza o status atual de cada bancada (executando, ociosa, etc.) de forma isolada e thread-safe."""
    try:
        with status_lock:
            # usa um arquivo separado por bancada para evitar conflito
            status_file = os.path.join(DATA_ROOT, f"status_{serial}.json")

            data = {}
            if os.path.exists(status_file):
                with open(status_file, "r", encoding="utf-8") as f:
                    try:
                        data = json.load(f)
                    except json.JSONDecodeError:
                        data = {}

            data.update({"status": status, "teste": teste, "atualizado_em": datetime.now().isoformat()})

            with open(status_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"âš ï¸ Erro ao atualizar status da bancada {serial}: {e}")



def _ollama_generate(prompt: str, timeout_s: int = 12, allow_cli: bool = True) -> str | None:
    payload = {"model": OLLAMA_MODEL, "prompt": prompt, "stream": False, "keep_alive": OLLAMA_KEEP_ALIVE, "options": {"num_predict": OLLAMA_NUM_PREDICT, "temperature": OLLAMA_TEMPERATURE, "top_p": OLLAMA_TOP_P, "num_ctx": OLLAMA_NUM_CTX}}
    urls = [OLLAMA_URL]
    if "localhost" in OLLAMA_URL:
        urls.append(OLLAMA_URL.replace("localhost", "127.0.0.1"))

    # Prefer requests if available
    if requests is not None:
        for url in urls:
            try:
                r = requests.post(f"{url}/api/generate", json=payload, timeout=timeout_s)
                r.raise_for_status()
                data = r.json()
                return data.get("response", "").strip() or None
            except Exception:
                pass

    # Fallback to stdlib urllib
    for url in urls:
        try:
            req = urllib.request.Request(
                f"{url}/api/generate",
                data=json.dumps(payload).encode("utf-8"),
                headers={"Content-Type": "application/json"},
                method="POST",
            )
            with urllib.request.urlopen(req, timeout=timeout_s) as resp:
                body = resp.read().decode("utf-8", errors="ignore")
                data = json.loads(body)
                return (data.get("response", "").strip() or None)
        except Exception:
            pass

    # CLI fallback (ollama run)
    if allow_cli:
        try:
            result = subprocess.run(
                [_resolve_ollama_cli(), "run", OLLAMA_MODEL],
                input=prompt,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=timeout_s
            )
            if result.returncode == 0:
                out = (result.stdout or "").strip()
                return out or None
        except Exception:
            pass

    return None


def llm_para_comando(frase: str, testes_disponiveis: list[str], categorias: list[str]) -> str | None:
    """
    Usa LLM local (Ollama) para transformar frase livre em comando can?nico.
    Retorna None se o LLM estiver indispon?vel ou com baixa confian?a.
    """
    prompt = f"""
Classifique em JSON.
Frase: "{frase}"
Comandos: executar/rodar, gravar/coletar, processar, apagar/deletar, listar categorias, listar testes, listar bancadas, resetar, pausar, retomar, parar.
Categorias: {categorias}
Testes: {testes_disponiveis[:25]}
Formato:
{{"acao":"executar|gravar|processar|apagar|listar_categorias|listar_testes|listar_bancadas|resetar|pausar|retomar|parar|nenhuma",
  "teste":"audio_1",
  "categoria":"audio",
  "bancada":"1|todas|",
  "confidence":0.0}}
""".strip()

    try:
        import json as _json
        resp = _ollama_generate(prompt, timeout_s=6, allow_cli=False)
        if not resp:
            return None
        parsed = _json.loads(resp)
    except Exception:
        return None

    if parsed.get("confidence", 0) < 0.6:
        return None

    acao = parsed.get("acao", "")
    teste = parsed.get("teste", "")
    categoria = parsed.get("categoria", "")
    bancada = parsed.get("bancada", "")

    if acao == "executar":
        return f"executar {teste} na bancada {bancada}".strip()
    if acao == "gravar":
        return f"gravar {teste} na bancada {bancada}".strip()
    if acao == "processar":
        return f"processar {teste}".strip()
    if acao == "apagar":
        return f"apagar {teste}".strip()
    if acao == "listar_categorias":
        return "listar categorias"
    if acao == "listar_testes":
        return f"listar testes de {categoria}".strip()
    if acao == "listar_bancadas":
        return "listar bancadas"
    if acao == "resetar":
        return f"resetar {teste} na bancada {bancada}".strip()
    if acao == "pausar":
        return "pausar"
    if acao == "retomar":
        return "retomar"
    if acao == "parar":
        return "parar"
    return None


def llm_responder_chat(frase: str) -> str | None:
    """
    Usa LLM local (Ollama) para responder conversa livre.
    Retorna None se indispon?vel.
    """
    prompt = f"""
Responda em pt-BR com no m?ximo 2 frases.
Se a pergunta for sobre uso, d? 1 exemplo de comando.
Usu?rio: "{frase}"
Assistente:
""".strip()

    try:
        resp = _ollama_generate(prompt, timeout_s=4, allow_cli=False)
        return resp or None
    except Exception:
        return None


def resolver_comando_com_llm_ou_fallback(texto: str) -> str:
    """Tenta LLM local e faz fallback para o parser atual."""
    try:
        cats = listar_categorias()
        testes_ex = []
        for c in cats:
            testes_ex.extend(listar_testes(c))
        cmd = llm_para_comando(texto, testes_ex, cats)
        if cmd:
            return interpretar_comando(cmd)
    except Exception:
        pass
    return interpretar_comando(texto)


def executar_teste(categoria, nome_teste, bancada: str | None = None):
    """
    Executa teste no host em background, permitindo paralelismo entre bancadas.
    Cada processo Ã© isolado e atualizado em status_bancadas.json.
    """
    caminho_teste = os.path.join(DATA_ROOT, categoria, nome_teste)
    dataset_path = os.path.join(caminho_teste, "dataset.csv")
    log_path = os.path.join(caminho_teste, "execucao_log.json")

    os.makedirs(caminho_teste, exist_ok=True)

    # 1ï¸âƒ£ Garante que o dataset existe antes da execuÃ§Ã£o
    if not os.path.exists(dataset_path):
        printc(f"âš™ï¸ Dataset nÃ£o encontrado para {categoria}/{nome_teste}, gerando automaticamente...", "yellow")
        processar_teste(categoria, nome_teste)

        # ğŸ•’ Aguarda dataset ser realmente criado (timeout 60s)
        for _ in range(60):
            if os.path.exists(dataset_path):
                printc("âœ… Dataset gerado com sucesso.", "green")
                break
            time.sleep(1)
        else:
            return f"âŒ O dataset de {categoria}/{nome_teste} nÃ£o foi gerado em tempo hÃ¡bil."

    # 2ï¸âƒ£ Mapeia bancadas ADB
    bancadas = listar_bancadas()
    seriais, erro = _selecionar_bancada(bancada, bancadas)
    if erro:
        return erro

    respostas = []

    for serial in seriais:
        # Evita executar 2 vezes na mesma bancada
        status_file = os.path.join(DATA_ROOT, f"status_{serial}.json")
        status_atual = {}
        if os.path.exists(status_file):
            try:
                with open(status_file, "r", encoding="utf-8") as f:
                    status_atual = json.load(f)
            except json.JSONDecodeError:
                print("âš ï¸ status_bancadas.json corrompido â€” recriando automaticamente.")
                status_atual = {}
            except Exception as e:
                print(f"âš ï¸ Erro ao ler status_bancadas.json: {e}")
                status_atual = {}
        else:
            print("â„¹ï¸ status_bancadas.json nÃ£o encontrado â€” criando novo.")
            status_atual = {}

        if str(status_atual.get("status", "")).lower() == "executando":
            respostas.append(f"âš ï¸ A bancada `{serial}` jÃ¡ estÃ¡ executando outro teste.")
            continue

        atualizar_status_bancada(serial, "executando", f"{categoria}/{nome_teste}")

        # Log inicial
        inicio = datetime.now().isoformat()
        log_entry = {
            "acao": "execucao_iniciada",
            "categoria": categoria,
            "teste": nome_teste,
            "serial": serial,
            "inicio": inicio
        }
        _registrar_log(log_path, log_entry)

        # ğŸš€ Executa em background isolado
        cmd = ["python", RUN_SCRIPT, categoria, nome_teste, "--serial", serial]
        try:
            proc = subprocess.Popen(
                cmd,
                cwd=BASE_DIR,
                start_new_session=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )

            # =============================
            # ğŸ§  MONITOR DE EXECUÃ‡ÃƒO (THREAD)
            # =============================
            def _monitor_processo(p, serial, categoria, nome_teste):
                stdout, stderr = p.communicate()
                if p.returncode != 0:
                    atualizar_status_bancada(serial, "erro")
                    printc(f"âŒ Erro na execuÃ§Ã£o do teste {categoria}/{nome_teste} na bancada {serial}.", "red")
                    print(stdout.decode(errors="ignore"))
                    print(stderr.decode(errors="ignore"))

                    # Envia mensagem para o chat (modo conversa)
                    if MODO_CONVERSA and "chat_history" in st.session_state:
                        st.session_state.chat_history.append({
                            "role": "assistant",
                            "content": f"âŒ O teste **{categoria}/{nome_teste}** falhou na bancada `{serial}`."
                        })
                else:
                    atualizar_status_bancada(serial, "finalizado")
                    printc(f"âœ… Teste {categoria}/{nome_teste} finalizado com sucesso na bancada {serial}.", "green")

                    # Envia mensagem para o chat (modo conversa)
                    if MODO_CONVERSA and "chat_history" in st.session_state:
                        st.session_state.chat_history.append({
                            "role": "assistant",
                            "content": f"âœ… Teste **{categoria}/{nome_teste}** finalizado com sucesso na bancada `{serial}`."
                        })

                    # Atualiza a interface automaticamente apÃ³s finalizaÃ§Ã£o
                    try:
                        st.rerun()
                    except Exception:
                        pass

            # ğŸ”¹ Inicia o monitoramento do processo (thread em background)
            threading.Thread(
                target=_monitor_processo,
                args=(proc, serial, categoria, nome_teste),
                daemon=True
            ).start()

            # Mensagem inicial
            respostas.append(f"â–¶ï¸ Executando **{categoria}/{nome_teste}** na bancada `{serial}` em background...")
            printc(f"ğŸš€ Teste {categoria}/{nome_teste} iniciado em {serial} (PID={proc.pid})", "cyan")

        except Exception as e:
            respostas.append(f"âŒ Falha ao iniciar execuÃ§Ã£o na bancada `{serial}`: {e}")
            atualizar_status_bancada(serial, "erro")

    return "\n".join(respostas)


def _registrar_log(caminho_log, nova_entrada):
    """Adiciona entrada ao execucao_log.json, criando se nÃ£o existir."""
    try:
        if os.path.exists(caminho_log):
            with open(caminho_log, "r", encoding="utf-8") as f:
                dados = json.load(f)
        else:
            dados = []

        dados.append(nova_entrada)

        with open(caminho_log, "w", encoding="utf-8") as f:
            json.dump(dados, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ Falha ao registrar log: {e}")


def iniciar_fluxo_gravacao():
    st.session_state.pending_gravacao = {"step": "categoria"}
    return "Qual categoria voce quer gravar?"


def continuar_fluxo_gravacao(resposta: str):
    pg = st.session_state.pending_gravacao or {"step": "categoria"}
    step = pg.get("step")

    if step == "categoria":
        categoria = resposta.strip().lower().replace(" ", "_")
        if not categoria:
            return "Informe a categoria do teste."
        pg["categoria"] = categoria
        pg["step"] = "nome"
        st.session_state.pending_gravacao = pg
        return "Qual nome do teste voce quer gravar?"

    if step == "nome":
        nome = resposta.strip().lower().replace(" ", "_")
        if not nome:
            return "Informe o nome do teste."
        pg["nome"] = nome

        bancadas = listar_bancadas()
        if len(bancadas) > 1:
            pg["step"] = "bancada"
            st.session_state.pending_gravacao = pg
            return "Qual bancada voce esta? (ex: 1, 2, 3)"

        # executa direto (0 ou 1 bancada)
        st.session_state.pending_gravacao = None
        return gravar_teste(pg["categoria"], pg["nome"], None)

    if step == "bancada":
        b = _extrair_bancada(resposta)
        if not b:
            return "Informe a bancada (ex: 1, 2, 3)."
        st.session_state.pending_gravacao = None
        return gravar_teste(pg["categoria"], pg["nome"], b)

    st.session_state.pending_gravacao = None
    return "Nao entendi. Tente novamente."


def checar_finalizacoes():
    """Verifica se resultado_final.png foi gerado e avisa no chat."""
    pend = list(st.session_state.finalizacoes_pendentes)
    restantes = []
    for item in pend:
        cat, nome, serial = item
        path_final = os.path.join(DATA_ROOT, cat, nome, "resultado_final.png")
        if os.path.exists(path_final):
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": f"Coleta finalizada: {cat}/{nome} (bancada {serial})."
            })
        else:
            restantes.append(item)
    st.session_state.finalizacoes_pendentes = restantes


def _adb_cmd(serial=None):
    if serial:
        return [ADB_PATH, "-s", serial]
    return [ADB_PATH]


def salvar_resultado_parcial(categoria, nome_teste, serial=None):
    """Salva uma screenshot de resultado esperado sem parar a grava??o."""
    base_dir = os.path.join(DATA_ROOT, categoria, nome_teste)
    esperados_dir = os.path.join(base_dir, "esperados")
    os.makedirs(esperados_dir, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    img_name = f"esperado_{ts}.png"
    img_path = os.path.join(esperados_dir, img_name)
    try:
        cmd = _adb_cmd(serial) + ["exec-out", "screencap", "-p"]
        with open(img_path, "wb") as f:
            subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE)
        if os.path.exists(img_path) and os.path.getsize(img_path) > 0:
            return f"Resultado esperado salvo: {img_name}"
        return "Falha ao salvar resultado esperado."
    except Exception as e:
        return f"Falha ao salvar resultado esperado: {e}"


def gravar_teste(categoria, nome_teste, bancada: str | None = None):
    """
    Grava teste no host, encaminhando o serial como parÃ¢metro para o coletor.
    Obs.: espera que Scripts/coletor_adb.py aceite '--serial <SERIAL>'.
    """
    # limpa flags antigas para nao encerrar a coleta imediatamente
    stop_path = os.path.join(PROJECT_ROOT, "stop.flag")
    if os.path.exists(stop_path):
        try:
            os.remove(stop_path)
        except Exception:
            pass

    bancadas = listar_bancadas()
    seriais, erro = _selecionar_bancada(bancada, bancadas)
    if erro:
        return erro

    respostas = []
    for serial in seriais:
        cmd = ["python", COLETOR_SCRIPT, categoria, nome_teste, "--serial", serial]
        ok, msg = _popen_host_python(cmd)
        if ok:
            respostas.append(f"ğŸ¥ Gravando **{categoria}/{nome_teste}** na bancada `{serial}`...")
        else:
            respostas.append(f"âŒ {msg}")
    return "\n".join(respostas)


def finalizar_gravacao(categoria=None, nome_teste=None, serial=None):
    """Encerra coletas ativas criando stop.flag (igual ao menu_tester)."""
    stop_path = os.path.join(PROJECT_ROOT, "stop.flag")
    try:
        with open(stop_path, "w") as f:
            f.write("stop")

        def _cleanup():
            try:
                time.sleep(15)
                if os.path.exists(stop_path):
                    os.remove(stop_path)
            except Exception:
                pass

        threading.Thread(target=_cleanup, daemon=True).start()
        if categoria and nome_teste and serial:
            st.session_state.finalizacoes_pendentes.append((categoria, nome_teste, serial))
        st.session_state.coleta_atual = None
        return "Finalizando gravacao... toque na tela do radio para capturar o print final."
    except Exception as e:
        return f"Falha ao finalizar gravacao: {e}"

def cancelar_gravacao(categoria=None, nome_teste=None):
    if categoria and nome_teste:
        try:
            caminho = os.path.join(DATA_ROOT, categoria, nome_teste)
            if os.path.exists(caminho):
                shutil.rmtree(caminho)
        except Exception:
            pass
    stop_path = os.path.join(PROJECT_ROOT, "stop.flag")
    try:
        with open(stop_path, "w") as f:
            f.write("stop")
    except Exception:
        pass
    st.session_state.coleta_atual = None
    return "Gravacao cancelada e teste removido."


def processar_teste(categoria, nome_teste):
    cmd = ["python", PROCESSAR_SCRIPT, categoria, nome_teste]
    ok, msg = _popen_host_python(cmd)
    if ok:
        return f"âš™ï¸ Processando dataset de **{categoria}/{nome_teste}**..."
    return f"âŒ {msg}"

def apagar_teste(categoria, nome_teste):
    caminho = os.path.join(DATA_ROOT, categoria, nome_teste)
    if os.path.exists(caminho):
        shutil.rmtree(caminho)
        return f"ğŸ—‘ï¸ Teste **{categoria}/{nome_teste}** apagado com sucesso."
    return f"âŒ Teste {categoria}/{nome_teste} nÃ£o encontrado."

def listar_categorias():
    if not os.path.isdir(DATA_ROOT):
        return []
    return [c for c in os.listdir(DATA_ROOT) if os.path.isdir(os.path.join(DATA_ROOT, c))]

def listar_testes(categoria):
    cat_path = os.path.join(DATA_ROOT, categoria)
    if os.path.isdir(cat_path):
        return [t for t in os.listdir(cat_path) if os.path.isdir(os.path.join(cat_path, t))]
    return []

def pausar_execucao():
    """
    Cria o arquivo pause.flag para pausar a execuÃ§Ã£o em andamento.
    """
    try:
        with open(PAUSE_FLAG_PATH, "w") as f:
            f.write("PAUSED")
        return "â¸ï¸ ExecuÃ§Ã£o pausada. O runner serÃ¡ interrompido no prÃ³ximo checkpoint."
    except Exception as e:
        return f"âŒ Falha ao pausar execuÃ§Ã£o: {e}"

def retomar_execucao():
    """
    Remove o arquivo pause.flag, permitindo continuar a execuÃ§Ã£o.
    """
    try:
        if os.path.exists(PAUSE_FLAG_PATH):
            os.remove(PAUSE_FLAG_PATH)
            return "â–¶ï¸ ExecuÃ§Ã£o retomada."
        else:
            return "âš ï¸ Nenhuma execuÃ§Ã£o estava pausada."
    except Exception as e:
        return f"âŒ Falha ao retomar execuÃ§Ã£o: {e}"

def parar_execucao():
    """
    Cria o arquivo stop.flag para parar completamente o runner.
    """
    stop_path = os.path.join(PROJECT_ROOT, "stop.flag")
    try:
        with open(stop_path, "w") as f:
            f.write("STOP")
        return "ğŸ›‘ ExecuÃ§Ã£o interrompida completamente."
    except Exception as e:
        return f"âŒ Falha ao interromper execuÃ§Ã£o: {e}"

# ======================================
# === FUNÃ‡Ã•ES AUXILIARES DO DASHBOARD ===
# ======================================
def carregar_logs(data_root=DATA_ROOT):
    logs = []
    if not os.path.isdir(data_root):
        return logs
    for categoria in os.listdir(data_root):
        cat_path = os.path.join(data_root, categoria)
        if os.path.isdir(cat_path):
            for teste in os.listdir(cat_path):
                teste_path = os.path.join(cat_path, teste)
                if os.path.isdir(teste_path):
                    arq = os.path.join(teste_path, "execucao_log.json")
                    if os.path.exists(arq):
                        logs.append((f"{categoria}/{teste}", arq))
    return logs

def calcular_metricas(execucao):
    total = len(execucao)
    acertos = sum(1 for a in execucao if "âœ…" in a.get("status", ""))
    falhas = total - acertos
    flakes = sum(1 for a in execucao if "FLAKE" in a.get("status", "")) if total > 0 else 0
    tempo_total = sum(a.get("duracao", 1) for a in execucao)
    cobertura = round((len({a.get("tela", f"id{a.get('id')}") for a in execucao}) / total) * 100, 1) if total > 0 else 0
    precisao = round((acertos / total) * 100, 2) if total > 0 else 0

    return {
        "total_acoes": total,
        "acertos": acertos,
        "falhas": falhas,
        "flakes": flakes,
        "precisao_percentual": precisao,
        "tempo_total": tempo_total,
        "cobertura_telas": cobertura,
        "resultado_final": "APROVADO" if falhas == 0 else "REPROVADO"
    }

def exibir_metricas(metricas):
    st.subheader("ğŸ“ˆ MÃ©tricas Gerais")
    col1, col2, col3 = st.columns(3)
    col1.metric("Total de AÃ§Ãµes", metricas["total_acoes"])
    col2.metric("Acertos", metricas["acertos"])
    col3.metric("Falhas", metricas["falhas"])

    col4, col5, col6 = st.columns(3)
    col4.metric("PrecisÃ£o (%)", metricas["precisao_percentual"])
    col5.metric("Flakes", metricas["flakes"])
    col6.metric("Cobertura de Telas (%)", metricas["cobertura_telas"])

    st.metric("â±ï¸ Tempo Total ExecuÃ§Ã£o (s)", metricas["tempo_total"])

    if metricas["resultado_final"] == "APROVADO":
        st.success("âœ… APROVADO")
    else:
        st.error("âŒ REPROVADO")

    fig, ax = plt.subplots()
    labels = ["Acertos", "Falhas"]
    sizes = [metricas["acertos"], metricas["falhas"]]
    colors = ["#4CAF50", "#F44336"]
    explode = (0.05, 0)
    ax.pie(sizes, explode=explode, labels=labels, colors=colors,
           autopct="%1.1f%%", shadow=True, startangle=90)
    ax.axis("equal")
    st.pyplot(fig)

def exibir_timeline(execucao):
    st.subheader("â³ Timeline da ExecuÃ§Ã£o")

    # Extrai e normaliza dados
    tempos = [int(float(a.get("duracao", 1))) for a in execucao]
    ids = []
    for idx, a in enumerate(execucao):
        # Garante que o ID seja numÃ©rico
        val = a.get("id", idx + 1)
        try:
            ids.append(int(val))
        except (ValueError, TypeError):
            ids.append(idx + 1)

    # Cores por status
    status = ["green" if "âœ…" in a.get("status", "") else "red" for a in execucao]

    # Cria o grÃ¡fico
    fig, ax = plt.subplots()
    ax.bar(ids, tempos, color=status)
    ax.set_xlabel("AÃ§Ã£o")
    ax.set_ylabel("DuraÃ§Ã£o (s)")
    ax.set_title("Tempo por AÃ§Ã£o")

    # Deixa o eixo X limpo (sem notaÃ§Ã£o cientÃ­fica)
    # Evita warnings de stub: nÃ£o usar set_useOffset diretamente
    # (o formato padrÃ£o jÃ¡ Ã© suficiente para o grÃ¡fico)

    st.pyplot(fig)

def exibir_acoes(execucao, base_dir):
    st.subheader("ğŸ“‹ Detalhes das AÃ§Ãµes")
    for acao in execucao:
        titulo = f"AÃ§Ã£o {acao.get('id')} - {str(acao.get('acao','')).upper()} | {acao.get('status','')}"
        with st.expander(titulo):
            col1, col2 = st.columns(2)

            frame_path = os.path.join(base_dir, acao.get("frame_esperado",""))
            resultado_path = os.path.join(base_dir, acao.get("screenshot",""))

            if frame_path and os.path.exists(frame_path):
                col1.image(Image.open(frame_path), caption=f"Esperado: {acao.get('frame_esperado','')}", use_container_width=True)
            else:
                col1.warning("Frame esperado nÃ£o encontrado")

            if resultado_path and os.path.exists(resultado_path):
                col2.image(Image.open(resultado_path), caption=f"Obtido: {acao.get('screenshot','')}", use_container_width=True)
            else:
                col2.warning("Screenshot nÃ£o encontrado")

            if "similaridade" in acao:
                st.write(f"ğŸ¯ Similaridade: **{acao['similaridade']:.2f}**")
            st.write(f"â±ï¸ DuraÃ§Ã£o: **{acao.get('duracao', 0)}s**")
            if "coordenadas" in acao:
                st.json(acao.get("coordenadas", {}))
            if "log" in acao:
                st.code(acao["log"], language="bash")

def exibir_mapa_calor(execucao):
    st.subheader("ğŸ”¥ Mapa de Calor dos Toques")
    xs = [a["coordenadas"]["x"] for a in execucao if "coordenadas" in a and "x" in a["coordenadas"]]
    ys = [a["coordenadas"]["y"] for a in execucao if "coordenadas" in a and "y" in a["coordenadas"]]

    if xs and ys:
        fig, ax = plt.subplots()
        sns.kdeplot(x=xs, y=ys, cmap="Reds", fill=True, ax=ax, thresh=0.05)
        ax.invert_yaxis()
        st.pyplot(fig)
    else:
        st.warning("Sem coordenadas para gerar mapa de calor.")

def exibir_validacao_final(execucao, base_dir):
    st.subheader("ğŸ–¼ï¸ ValidaÃ§Ã£o Final da Tela")
    resultado_final_path = os.path.join(base_dir, "resultado_final.png")

    col1, col2 = st.columns(2)
    if execucao:
        ultima = execucao[-1]
        frame_path = os.path.join(base_dir, ultima.get("frame_esperado",""))

        if frame_path and os.path.exists(frame_path):
            col1.image(Image.open(frame_path), caption="Esperada (Ãšltima AÃ§Ã£o)", use_container_width=True)
        else:
            col1.error("Frame esperado nÃ£o encontrado")

        if os.path.exists(resultado_final_path):
            col2.image(Image.open(resultado_final_path), caption="Obtida (Resultado Final)", use_container_width=True)
        else:
            col2.error("resultado_final.png nÃ£o encontrado")

        if "similaridade" in ultima:
            st.write(f"ğŸ¯ Similaridade Final: **{ultima['similaridade']:.2f}**")
        if "âœ…" in ultima.get("status",""):
            st.success("âœ… Tela final validada")
        else:
            st.error("âŒ Tela final divergente")
    else:
        st.warning("Nenhuma aÃ§Ã£o registrada")

def exibir_regressoes(execucao):
    st.subheader("ğŸ“‰ AnÃ¡lise de RegressÃµes")
    falhas = [a for a in execucao if "âŒ" in a.get("status","")]
    if falhas:
        st.write("Top falhas nesta execuÃ§Ã£o:")
        for f in falhas:
            sim = f.get("similaridade")
            sim_str = f"{sim:.2f}" if isinstance(sim, (int, float)) else "N/A"
            st.write(f"- AÃ§Ã£o {f.get('id')} ({f.get('acao','')}): Similaridade {sim_str}")
    else:
        st.success("Nenhuma falha registrada")

# ===========================
# === PARSER DE COMANDOS  ===
# ===========================
# Palavras-chave com variaÃ§Ãµes comuns (sem acento e lower)
KW_EXECUTAR = [
    "executar", "execute", "rodar", "rode", "run", "iniciar teste",
    "inicia o teste", "comeÃ§a o teste", "roda o teste", "faz o teste",
    "testa", "teste agora", "starta o teste", "comeÃ§ar teste", "faÃ§a o teste",
    "rodar tudo", "rodar todos", "rodar todos os testes", "executa tudo"
]

KW_GRAVAR = [
    "gravar", "grave", "coletar", "colete", "capturar", "record",
    "comeÃ§ar gravaÃ§Ã£o", "iniciar gravaÃ§Ã£o", "grava agora", "fazer gravaÃ§Ã£o",
    "fazer coleta", "comeÃ§ar coleta", "startar gravaÃ§Ã£o", "inicia a coleta",
    "comeÃ§a a gravar", "grava o gesto", "grava o teste"
]

KW_PROCESS = [
    "processar", "processa", "prÃ©-processar", "preprocessar", "pre", "gerar dataset",
    "processa o dataset", "gera o dataset", "montar dataset", "gerar base",
    "monta o csv", "gerar csv", "converter dados", "processa os dados"
]

KW_APAGAR = [
    "apagar", "apague", "deletar", "delete", "remover", "remova", "excluir", "exclua",
    "apaga", "apaga o teste", "deleta o teste", "limpa", "limpar teste", "remove o teste",
    "apagar teste", "excluir teste", "deleta tudo"
]

KW_LISTAR = [
    "listar", "liste", "mostrar", "mostre", "exibir", "exiba", "lista", "me mostra",
    "me exibe", "quais sÃ£o", "ver", "ver lista", "ver testes", "mostra pra mim",
    "quero ver", "ver categorias", "mostrar categorias", "mostrar testes"
]

KW_BANCADAS = [
    "bancada", "bancadas", "devices", "dispositivos", "adb", "hardware conectado",
    "listar bancadas", "mostrar bancadas", "listar dispositivos", "mostrar dispositivos",
    "quais bancadas", "tem bancada", "quais estÃ£o conectadas", "ver bancadas",
    "ver dispositivos", "me mostra as bancadas", "fala as bancadas", "lista as bancadas"
]

KW_AJUDA = [
    "ajuda", "help", "comandos", "o que posso dizer", "fala os comandos",
    "me ajuda", "quais comandos", "mostra os comandos", "explica comandos",
    "fala os exemplos", "ensina", "socorro"
]

_NUM_PT = {
    "zero":"0","um":"1","uma":"1","dois":"2","duas":"2","tres":"3","trÃªs":"3",
    "quatro":"4","cinco":"5","seis":"6","sete":"7","oito":"8","nove":"9","dez":"10",
    "onze":"11","doze":"12","treze":"13","catorze":"14","quatorze":"14","quinze":"15",
    "dezesseis":"16","dezessete":"17","dezoito":"18","dezenove":"19","vinte":"20"
}

def _replace_number_words(s: str) -> str:
    """Troca nÃºmeros por extenso (pt-BR) por dÃ­gitos no texto normalizado."""
    for k, v in _NUM_PT.items():
        s = re.sub(rf"\b{k}\b", v, s)
    return s

def _normalize_token(s: str) -> str:
    """Normaliza nomes de teste para comparaÃ§Ã£o: lower, sem acentos e sem separadores."""
    s = _norm(s)
    s = re.sub(r"[\s_-]+", "", s)  # remove espaÃ§o, _ e -
    return s

def _norm(s: str) -> str:
    """Lower + remove acentos para matching robusto."""
    s = s.strip().lower()
    return normalize("NFKD", s).encode("ASCII", "ignore").decode("ASCII")

from difflib import SequenceMatcher

def _has_any(texto_norm: str, termos: list[str]) -> bool:
    texto_norm = _norm(texto_norm)
    termos_norm = [_norm(t) for t in termos]
    for termo in termos_norm:
        ratio = SequenceMatcher(None, texto_norm, termo).ratio()
        if termo in texto_norm or ratio > 0.8:
            return True
    return False

def _extrair_bancada(texto: str) -> str | None:
    """
    Extrai a bancada do comando.
    Suporta: "na bancada 2", "bancada=2", "bancada2", "todas as bancadas", "bancada um".
    Retorna "2", "todas" ou None.
    """
    t = _replace_number_words(_norm(texto))

    # todas as bancadas
    if re.search(r"\btodas(\s+as\s+)?bancadas\b", t) or re.search(r"\ball\b", t):
        return "todas"

    m = re.search(r"bancada\s*=\s*(\d+)", t)
    if m:
        return m.group(1)

    m = re.search(r"\bbancada\s*(\d+)\b", t)
    if m:
        return m.group(1)

    return None

def _extrair_token_teste(texto: str) -> str | None:
    """
    Extrai o nome do teste em diferentes formatos e devolve forma canÃ´nica 'base_numero':
    - geral_2, geral-2, geral2, geral 2, geral um  -> sempre retorna 'geral_2'
    """
    t = _replace_number_words(_norm(texto))

    # 1) com _ ou -
    m = re.search(r"\b([a-z0-9]+)[_\-]([0-9]+)\b", t)
    if m:
        return f"{m.group(1)}_{m.group(2)}"

    # 2) colado: 'geral2'
    m = re.search(r"\b([a-z]+)(\d+)\b", t)
    if m:
        return f"{m.group(1)}_{m.group(2)}"

    # 3) com espaÃ§o: 'geral 2'
    m = re.search(r"\b([a-z]+)\s+(\d+)\b", t)
    if m:
        return f"{m.group(1)}_{m.group(2)}"

    return None

def _extrair_categoria(texto: str) -> str | None:
    """
    Se o usuÃ¡rio pedir 'testes de <categoria>' ou mencionar explicitamente uma categoria existente.
    """
    t = _norm(texto)
    # padrÃ£o 'de <categoria>'
    m = re.search(r"\bde\s+([a-z0-9_-]+)\b", t)
    if m and m.group(1) in listar_categorias():
        return m.group(1)
    # ou se o nome da categoria aparecer diretamente no texto
    for cat in listar_categorias():  
        if _norm(cat) in t:
            return cat
    return None

def interpretar_comando(comando: str):
    texto = comando.strip()
    texto_norm = _norm(texto)

    # 1) AJUDA
    if _has_any(texto_norm, KW_AJUDA):
        return (
            "ğŸ§­ **Comandos suportados**\n"
            "- **executar/rodar** `<teste>` [na bancada N|todas]\n"
            "- **gravar/coletar** `<teste>` [na bancada N|todas]\n"
            "- **processar** `<teste>`\n"
            "- **apagar/deletar/remover** `<teste>`\n"
            "- **listar/mostrar** categorias | testes [de <categoria>]\n"
            "- **listar bancadas**\n"
            "Ex.: `execute o teste audio_1 na bancada 2`"
        )

    # 2) LISTAR BANCADAS
    if _has_any(texto_norm, ["listar bancadas", "mostrar bancadas", "listar devices", "mostrar devices"]) \
       or (_has_any(texto_norm, KW_LISTAR) and any(k in texto_norm for k in ["bancada", "bancadas", "devices", "dispositivos"])):  
        return _formatar_bancadas_str(listar_bancadas())

    # 3) EXECUTAR (rodar testes)
    if _has_any(texto_norm, KW_EXECUTAR):
        # Caso especial: "todos os testes da categoria X"
        if re.search(r"todos\s+os\s+testes\s+da\s+categoria", texto_norm):
            cat = _extrair_categoria(texto)
            if not cat:
                return "âš ï¸ Especifique a categoria (ex: rodar todos os testes da categoria audio)."

            testes = listar_testes(cat)
            if not testes:
                return f"ğŸ“‚ A categoria **{cat}** nÃ£o possui testes."

            bancada = _extrair_bancada(texto)
            respostas = [f"â–¶ï¸ Rodando todos os testes da categoria **{cat}** na bancada {bancada or '(padrÃ£o)'}..."]

            for t in testes:
                respostas.append(executar_teste(cat, t, bancada))

            return "\n".join(respostas)

        # âœ… Caso normal: executar um teste especÃ­fico (ex: "executar teste geral_1" ou "executar geral 2")
        token = _extrair_token_teste(texto)
        if token:
            cat, nome = _resolver_teste(token)
            if cat and nome:
                bancada = _extrair_bancada(texto)
                return executar_teste(cat, nome, bancada)
            else:
                # tentativa extra: se o usuÃ¡rio disse apenas "geral 2" sem categoria explÃ­cita
                # busca qualquer teste com nome igual em todas as categorias
                for cat_try in listar_categorias():
                    if token in listar_testes(cat_try):
                        bancada = _extrair_bancada(texto)
                        return executar_teste(cat_try, token, bancada)
                return f"âŒ Teste **{token}** nÃ£o encontrado em `Data/*/`."
        return "âš ï¸ Especifique o teste a executar (ex: `executar teste geral_1 na bancada 1`)."

    # 4) GRAVAR / COLETAR
    if _has_any(texto_norm, KW_GRAVAR):
        token = _extrair_token_teste(texto)
        if token:
            if "_" in token:
                cat, nome = token.split("_", 1)
            else:
                return "âš ï¸ Use o formato categoria_nome (ex: audio_3)."

            bancada = _extrair_bancada(texto)
            return gravar_teste(cat, token, bancada)

        return "âš ï¸ Especifique o teste (ex: `gravar audio_1 na bancada 1`)."

    # 5) PROCESSAR (gera dataset)
    if _has_any(texto_norm, KW_PROCESS):
        token = _extrair_token_teste(texto)
        if token:
            if "_" in token:
                cat, nome = token.split("_", 1)
                return processar_teste(cat, token)
            return "âš ï¸ Use o formato categoria_nome (ex: audio_3)."
        return "âš ï¸ Especifique o teste (ex: `processar audio_1`)."

    # 6) APAGAR / DELETAR
    if _has_any(texto_norm, KW_APAGAR):
        token = _extrair_token_teste(texto)
        if token:
            cat, teste = _resolver_teste(token)
            if cat and teste:
                return apagar_teste(cat, teste)
            return f"âŒ NÃ£o encontrei o teste **{token}** em `Data/*/`."
        return "âš ï¸ Especifique o teste (ex: `apagar audio_1`)."

    # 7) LISTAR / MOSTRAR
    if _has_any(texto_norm, KW_LISTAR):
        cat = _extrair_categoria(texto)
        if cat:
            testes = listar_testes(cat)
            if testes:
                return f"ğŸ“ Testes em **{cat}**:\n- " + "\n- ".join(testes)
            return f"ğŸ“‚ A categoria **{cat}** nÃ£o possui testes."
        cats = listar_categorias()
        if cats:
            return "ğŸ“‚ Categorias disponÃ­veis:\n- " + "\n- ".join(cats)
        return "ğŸ“‚ Nenhuma categoria encontrada em `Data/`."

    # âœ… RESETAR INTERFACE / REVERTER AÃ‡Ã•ES
    if any(_norm(p) in texto_norm for p in ["reset", "resetar", "reverter", "restaurar", "desfazer"]):
        token = _extrair_token_teste(texto)
        if token:
            cat, nome = _resolver_teste(token)
            if cat and nome:
                bancada = _extrair_bancada(texto)
                try:
                    cmd = ["python", RUN_SCRIPT, "--reset", cat, nome]
                    if bancada:
                        cmd += ["--serial", bancada]
                    subprocess.Popen(cmd, cwd=BASE_DIR)
                    return f"â™»ï¸ Reset comportamental iniciado para **{cat}/{nome}** na bancada `{bancada or 'padrÃ£o'}`."
                except Exception as e:
                    return f"âŒ Erro ao iniciar reset: {e}"
            else:
                return f"âŒ Teste **{token}** nÃ£o encontrado."
        else:
            return "âš ï¸ Especifique o teste para resetar (ex: `reset geral_1 na bancada 1`)."

    # 8) CONTROLE DE EXECUÃ‡ÃƒO (pausar, retomar, parar)
    if any(_norm(p) in texto_norm for p in ["pausar", "pause", "parar teste", "interromper", "stop"]):
        return pausar_execucao()

    if any(_norm(p) in texto_norm for p in ["retomar", "continuar", "resume", "seguir"]):
        return retomar_execucao()

    if any(_norm(p) in texto_norm for p in ["cancelar", "encerrar", "finalizar", "stop all", "terminar"]):
        return parar_execucao()

    return "âŒ NÃ£o entendi o comando. Digite **ajuda** para ver exemplos."

def responder_conversacional(comando: str):
    """
    Interpreta comandos em linguagem natural e responde de forma humana,
    mantendo integraÃ§Ã£o com o interpretador tÃ©cnico.
    """

    # CorreÃ§Ãµes automÃ¡ticas comuns de fala
    substituicoes_voz = {
        "star bancadas": "listar bancadas",
        "esta bancadas": "listar bancadas",
        "instalar bancadas": "listar bancadas",
        "histÃ³ria bancadas": "listar bancadas",
        "listar bancada": "listar bancadas",
        "listra bancadas": "listar bancadas",
        "ver bancadas": "listar bancadas",
        "mostra bancadas": "listar bancadas",
        "voltar": "resetar",
        "voltar teste": "resetar",
        "voltar o teste": "resetar",
        "voltar geral": "resetar geral",
        "volta geral": "resetar geral",
        "reset": "resetar",
        "refazer estado": "resetar",
    }

    for errado, certo in substituicoes_voz.items(): 
        if errado in comando.lower():
            comando = comando.lower().replace(errado, certo)


    comando_norm = _norm(comando)

    # fluxo guiado de gravacao
    if st.session_state.pending_gravacao is not None:
        return continuar_fluxo_gravacao(comando)

    # ExpressÃµes auxiliares para respostas naturais
    frases_iniciais = [
        "Entendido ğŸ’«",
        "Certo!",
        "Perfeito ğŸ˜",
        "Beleza âš™ï¸",
        "Ok, jÃ¡ vou cuidar disso ğŸ‘‡"
    ]

    frases_execucao = [
        "Iniciando o teste agora ğŸš€",
        "Rodando o caso de teste no rÃ¡dio...",
        "Executando o cenÃ¡rio solicitado ğŸ’»",
        "ComeÃ§ando a sequÃªncia de validaÃ§Ãµes..."
    ]

    frases_coleta = [
        "Iniciando gravaÃ§Ã£o ğŸ¥",
        "Pode tocar na tela â€” estou coletando os gestos.",
        "Gravando as interaÃ§Ãµes agora ğŸ‘‡"
    ]

    frases_processamento = [
        "Gerando o dataset, aguarde um instante âš™ï¸",
        "Transformando os logs em dados Ãºteis...",
        "Processando o dataset pra vocÃª ğŸ’¾"
    ]

    frases_bancadas = [
        "Consultando bancadas ADB conectadas ğŸ“¡",
        "Um segundo... vou listar as bancadas disponÃ­veis ğŸ”",
        "Beleza, verificando conexÃµes com as bancadas âš™ï¸"
    ]

    frases_ajuda = [
        "Aqui estÃ¡ o que posso fazer ğŸ‘‡",
        "Claro! Aqui estÃ£o alguns comandos que vocÃª pode usar ğŸ§­",
        "Lista de comandos Ã  disposiÃ§Ã£o ğŸ‘‡"
    ]

    respostas_rapidas = {
        "oi": "Ol?!  Posso ajudar com testes ou explicar comandos. Ex.: `executar audio_1 na bancada 1`",
        "ola": "Ol?!  Posso ajudar com testes ou explicar comandos. Ex.: `executar audio_1 na bancada 1`",
        "ol?": "Ol?!  Posso ajudar com testes ou explicar comandos. Ex.: `executar audio_1 na bancada 1`",
        "eai": "Fala!  Se quiser rodar algo: `executar audio_1 na bancada 1`",
        "e a?": "Fala!  Se quiser rodar algo: `executar audio_1 na bancada 1`",
        "bom dia": "Bom dia! Posso ajudar com testes ou comandos.",
        "boa tarde": "Boa tarde! Posso ajudar com testes ou comandos.",
        "boa noite": "Boa noite! Posso ajudar com testes ou comandos.",
        "tudo bem": "Tudo sim! Posso ajudar com testes ou comandos.",
        "beleza": "Beleza! Posso ajudar com testes ou comandos.",
        "blz": "Blz! Posso ajudar com testes ou comandos."
    }

    saudacoes_rapidas = ["oi", "ola", "ol?", "eai", "e a?", "bom dia", "boa tarde", "boa noite", "tudo bem", "beleza", "blz"]
    comando_norm_limpo = re.sub(r"[^a-z0-9\s]", "", comando_norm).strip()
    for s in saudacoes_rapidas:
        if comando_norm_limpo == s or comando_norm_limpo.startswith(s + " "):
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": respostas_rapidas.get(s, "Ol?!  Posso ajudar com testes ou comandos.")
            })
            return ""

    # Permite frases como "Zuri, listar bancadas"
    if comando_norm.startswith("zuri"):
        comando_norm = comando_norm.replace("zuri", "", 1).strip()

    # === ROTEAMENTO ===
    if any(p in comando_norm for p in ["listar bancadas", "ver bancadas", "bancadas conectadas"]):
        resposta_pre = random.choice(frases_bancadas)
        st.session_state.chat_history.append({"role": "assistant", "content": resposta_pre})
        return resolver_comando_com_llm_ou_fallback("listar bancadas")

    # â™»ï¸ RESETAR TESTE / REVERTER AÃ‡Ã•ES
    if any(p in comando_norm for p in ["reset", "resetar", "reverter", "restaurar", "desfazer", "voltar estado inicial"]):
        resposta_pre = f"{random.choice(frases_iniciais)} â™»ï¸ Restaurando estado inicial do teste..."
        st.session_state.chat_history.append({"role": "assistant", "content": resposta_pre})
        if _extrair_token_teste(comando) is None and "gravar" in comando_norm:
            return iniciar_fluxo_gravacao()
        return resolver_comando_com_llm_ou_fallback(comando)

    if any(p in comando_norm for p in ["executar", "rodar", "testar", "rodar o teste"]):
        resposta_pre = f"{random.choice(frases_iniciais)} {random.choice(frases_execucao)}"
        st.session_state.chat_history.append({"role": "assistant", "content": resposta_pre})
        if _extrair_token_teste(comando) is None and "gravar" in comando_norm:
            return iniciar_fluxo_gravacao()
        return resolver_comando_com_llm_ou_fallback(comando)

    if any(p in comando_norm for p in ["gravar teste", "gravar", "coletar teste", "coletar", "capturar"]):
        resposta_pre = f"{random.choice(frases_iniciais)} {random.choice(frases_coleta)}"
        st.session_state.chat_history.append({"role": "assistant", "content": resposta_pre})
        if _extrair_token_teste(comando) is None and "gravar" in comando_norm:
            return iniciar_fluxo_gravacao()
        return resolver_comando_com_llm_ou_fallback(comando)

    if any(p in comando_norm for p in ["processar", "gerar dataset", "montar csv"]):
        resposta_pre = f"{random.choice(frases_iniciais)} {random.choice(frases_processamento)}"
        st.session_state.chat_history.append({"role": "assistant", "content": resposta_pre})
        if _extrair_token_teste(comando) is None and "gravar" in comando_norm:
            return iniciar_fluxo_gravacao()
        return resolver_comando_com_llm_ou_fallback(comando)

    if any(p in comando_norm for p in ["ajuda", "comandos", "socorro", "me ajuda"]):
        resposta_pre = random.choice(frases_ajuda)
        st.session_state.chat_history.append({"role": "assistant", "content": resposta_pre})
        return resolver_comando_com_llm_ou_fallback("ajuda")

    # Caso n?o tenha correspond?ncia
    resposta_llm = llm_responder_chat(comando) if MODO_CONVERSA else None
    if resposta_llm:
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": resposta_llm
        })
        return ""

    st.session_state.chat_history.append({
        "role": "assistant",
        "content": "Posso ajudar com comandos de testes. Ex.: `executar audio_1 na bancada 1`"
    })
    return ""

# ==================
# === UI LATERAL  ===
# ==================
st.sidebar.title("â˜° VWAIT - Menu")
pagina = st.sidebar.radio("Navegacao", ["Chat", "Dashboard", "Menu Tester"])

# Botao de voz (sidebar)
mic_clicked = st.sidebar.button("Falar comando")

if mic_clicked:
    recognizer = configurar_reconhecedor()
    try:
        mic = sr.Microphone()
    except Exception as e:
        st.session_state.chat_history.append({"role": "assistant", "content": f"Microfone indisponivel: {e}"})
        st.rerun()

    with mic as source:
        st.toast("Ouvindo... fale seu comando completo.")
        recognizer.adjust_for_ambient_noise(source, duration=1)
        audio = recognizer.listen(source, phrase_time_limit=12)

    try:
        st.toast("Reconhecendo fala...")
        command_text = recognizer.recognize_google(audio, language="pt-BR")  # type: ignore[attr-defined]
        command_text = normalizar_pos_fala(command_text)
        st.session_state.chat_history.append({"role": "user", "content": command_text})
        with st.spinner("Processando comando..."):
            if st.session_state.pending_gravacao is not None:
                resposta = continuar_fluxo_gravacao(command_text)
            elif MODO_CONVERSA:
                resposta = responder_conversacional(command_text)
            else:
                resposta = resolver_comando_com_llm_ou_fallback(command_text)
        if resposta:
            st.session_state.chat_history.append({"role": "assistant", "content": resposta})
        st.rerun()
    except Exception:
        st.session_state.chat_history.append({"role": "assistant", "content": "Falha ao reconhecer fala."})
        st.rerun()


# Side info: bancadas
with st.sidebar.expander("ğŸ“¡ Bancadas (ADB)"):
    st.markdown(_formatar_bancadas_str(listar_bancadas()))
    if st.button("ğŸ”„ Atualizar lista de bancadas"):
        st.rerun()

# ============
# === CHAT ===
# ============
if pagina == "Chat":
    titulo_painel("VWAIT - Agente de Testes", "Digite <b>ajuda</b> para ver exemplos de comandos.")

    # === EXEMPLOS DE PROMPTS ESTILIZADOS ===
    st.markdown(
        """
        <div style="
            background-color: rgba(50, 50, 50, 0.6);
            border: 1px solid rgba(100, 100, 100, 0.5);
            border-radius: 10px;
            padding: 20px;
            margin-top: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.4);
        ">
            <h3 style="color:#E0E0E0; margin-bottom:8px;">Exemplos de comandos</h3>
            <ul style="color:#CCCCCC; line-height:1.6; font-size:15px;">
                <li><code>gravar audio_1 na bancada 1</code> - inicia gravacao do teste de audio na bancada 1</li>
                <li><code>processar audio_1</code> - processa o dataset coletado</li>
                <li><code>executar audio_1 na bancada 1</code> - roda o teste gravado</li>
                <li><code>rodar todos os testes da categoria video</code> - executa todos os testes de uma categoria</li>
                <li><code>listar bancadas</code> - mostra bancadas ADB conectadas</li>
                <li><code>ajuda</code> - exibe a lista completa de comandos</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    checar_finalizacoes()
    # === Exibio do hist?rico ===
    for idx, msg in enumerate(st.session_state.chat_history):
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg["role"] == "assistant" and "Gravando" in msg["content"]:
                m = re.search(r"Gravando\s+([a-z0-9_]+)/([a-z0-9_]+)\s+na bancada\s+([0-9A-Fa-f]+)", msg["content"])
                cat = nome = serial = None
                if m:
                    cat, nome, serial = m.group(1), m.group(2), m.group(3)
                if st.button("Salvar esperado", key=f"esperado_{idx}"):
                    msg_resp = salvar_resultado_parcial(cat, nome, serial)
                    st.session_state.chat_history.append({"role": "assistant", "content": msg_resp})
                    st.rerun()
                if st.button("Finalizar gravacao", key=f"finalizar_{idx}"):
                    msg_resp = finalizar_gravacao(cat, nome, serial)
                    st.session_state.chat_history.append({"role": "assistant", "content": msg_resp})
                    st.rerun()
                if st.button("Cancelar gravacao", key=f"cancelar_{idx}"):
                    msg_resp = cancelar_gravacao(cat, nome)
                    st.session_state.chat_history.append({"role": "assistant", "content": msg_resp})
                    st.rerun()

        processing_placeholder = st.empty()
    user_input = st.chat_input("Digite seu comando...")

    #  ENTRADA MANUAL
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        with st.spinner("Processando comando..."):
            if st.session_state.pending_gravacao is not None:
                resposta = continuar_fluxo_gravacao(user_input)
            elif MODO_CONVERSA:
                resposta = responder_conversacional(user_input)
            else:
                resposta = resolver_comando_com_llm_ou_fallback(user_input)

        if resposta:
            st.session_state.chat_history.append({"role": "assistant", "content": resposta})
        st.rerun()

elif pagina == "ğŸ“Š Dashboard":
    st.title("ğŸ“Š Dashboard de ExecuÃ§Ã£o de Testes - RÃ¡dio Android")

    logs = carregar_logs()
    if not logs:
        st.error("Nenhum execucao_log.json encontrado em Data/*/*/")
        st.stop()

    opcao = st.selectbox("Selecione a execuÃ§Ã£o", [r[0] for r in logs])
    log_path = dict(logs)[opcao]

    with open(log_path, "r", encoding="utf-8") as f:
        execucao = json.load(f)

    base_dir = os.path.dirname(log_path)

    metricas = calcular_metricas(execucao)
    exibir_metricas(metricas)
    exibir_timeline(execucao)
    exibir_acoes(execucao, base_dir)
    exibir_mapa_calor(execucao)
    exibir_validacao_final(execucao, base_dir)
    exibir_regressoes(execucao)

    if st.button("ğŸ“¤ Exportar RelatÃ³rio JSON"):
        st.download_button("Baixar JSON", data=json.dumps(execucao, indent=2), file_name="relatorio_execucao.json")
